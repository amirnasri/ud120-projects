{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#cv = KFold(n_splits=10)\n",
      "#estimator = GaussianNB()\n",
      "from sklearn import linear_model\n",
      "C_vec = np.logspace(-2, 1, 4)\n",
      "markers = list('o^+s')\n",
      "for i, C in enumerate(C_vec):\n",
      "    \n",
      "    estimator = linear_model.LogisticRegression(C=C)\n",
      "    plot_learning_curve(estimator, title, X, y, C, markers[i], ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
      "    plt.hold()\n",
      "\n",
      "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
      "# SVC is more expensive so we do a lower number of CV iterations:\n",
      "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
      "estimator = SVC(gamma=0.001)\n",
      "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "LogisticRegression(C=0.0039810717055349734, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, marker, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    #plt.figure()\n",
    "    #plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.hold(True)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    '''\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    '''\n",
    "    plt.plot(train_sizes, train_scores_mean, marker + '-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, marker + '-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "estimator = linear_model.LogisticRegression()\n",
    "parameters = {'C':np.logspace(-3, 0, 6)}\n",
    "gs = GridSearchCV(estimator, parameters, verbose=True)\n",
    "gs.fit(X, y)\n",
    "\n",
    "best_estimator = gs.best_estimator_\n",
    "print(best_estimator)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.2)\n",
    "plot_learning_curve(best_estimator, title, X, y, 'o', ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "#cv = KFold(n_splits=10)\n",
    "#estimator = GaussianNB()\n",
    "from sklearn import linear_model\n",
    "C_vec = np.logspace(-2, 1, 4)\n",
    "markers = list('o^+s')\n",
    "for i, C in enumerate(C_vec):\n",
    "    \n",
    "    estimator = linear_model.LogisticRegression(C=C)\n",
    "    plot_learning_curve(estimator, title, X, y, C, markers[i], ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "    plt.hold()\n",
    "\n",
    "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.05000464,  0.06220333,  0.07317464,  0.08594139,  0.15809107,\n",
       "         0.13667035]),\n",
       " 'mean_score_time': array([ 0.000494  ,  0.0005254 ,  0.00051371,  0.00051037,  0.00054169,\n",
       "         0.00051109]),\n",
       " 'mean_test_score': array([ 0.92209238,  0.92988314,  0.92932666,  0.92654424,  0.92042293,\n",
       "         0.91819699]),\n",
       " 'mean_train_score': array([ 0.96382567,  0.97746166,  0.98636402,  0.99387936,  0.99721548,\n",
       "         0.99805091]),\n",
       " 'param_C': masked_array(data = [0.001 0.0039810717055349734 0.015848931924611134 0.063095734448019303\n",
       "  0.25118864315095796 1.0],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 0.001},\n",
       "  {'C': 0.0039810717055349734},\n",
       "  {'C': 0.015848931924611134},\n",
       "  {'C': 0.063095734448019303},\n",
       "  {'C': 0.25118864315095796},\n",
       "  {'C': 1.0}),\n",
       " 'rank_test_score': array([4, 1, 2, 3, 5, 6], dtype=int32),\n",
       " 'split0_test_score': array([ 0.9269103 ,  0.9269103 ,  0.92026578,  0.91528239,  0.90199336,\n",
       "         0.89534884]),\n",
       " 'split0_train_score': array([ 0.96317992,  0.9790795 ,  0.98577406,  0.99414226,  0.9958159 ,\n",
       "         0.99748954]),\n",
       " 'split1_test_score': array([ 0.93823038,  0.94824708,  0.94824708,  0.94657763,  0.94991653,\n",
       "         0.94991653]),\n",
       " 'split1_train_score': array([ 0.96160267,  0.97328881,  0.98497496,  0.99415693,  0.99749583,\n",
       "         0.99749583]),\n",
       " 'split2_test_score': array([ 0.90100671,  0.91442953,  0.91946309,  0.91778523,  0.90939597,\n",
       "         0.90939597]),\n",
       " 'split2_train_score': array([ 0.96669442,  0.98001665,  0.98834305,  0.99333888,  0.99833472,\n",
       "         0.99916736]),\n",
       " 'std_fit_time': array([ 0.00432309,  0.0060542 ,  0.00176824,  0.00265205,  0.07337203,\n",
       "         0.0204977 ]),\n",
       " 'std_score_time': array([  3.37214123e-05,   4.15999240e-05,   2.41861387e-05,\n",
       "          6.34490129e-06,   2.30523356e-05,   1.05845200e-05]),\n",
       " 'std_test_score': array([ 0.01555788,  0.01394913,  0.01338277,  0.01420255,  0.02107295,\n",
       "         0.02315061]),\n",
       " 'std_train_score': array([ 0.00212826,  0.00297534,  0.00143691,  0.00038222,  0.00104724,\n",
       "         0.00078945])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i>fdas<i/>\n"
     ]
    }
   ],
   "source": [
    "print('<i>fdas<i/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>fdas<i/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
